{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intel&reg; OSPRay Introduction\n",
    "--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Define the goals of Intel® OSPRay.\n",
    "* Summarize the program flow and OSPRay API use in the ospTutorial.cpp code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 1. Intel&reg; OSPRay overview\n",
    "\n",
    "Intel OSPRay is an open source ray tracing engine for high-performance, high-fidelity visualization on Intel Architecture CPUs.  OSPRay is part of the Intel oneAPI Rendering Toolkit and is released under the permissive Apache 2.0 license.\n",
    "\n",
    "<!-- The purpose of OSPRay is to provide an open, powerful, and easy-to-use rendering library that allows one to easily build applications that use ray tracing rendering for interactive applications, including both surface-based and volume-based visualizations. OSPRay is completely CPU-based, and runs on anything from laptops, to workstations, to compute nodes in HPC systems. -->\n",
    "\n",
    "The purpose of OSPRay is to provide an easy-to-use rendering library that allows to easily build applications that use ray tracing rendering for interactive applications, including both surface-based and volume-based visualizations.\n",
    "\n",
    "<!-- OSPRay internally builds on top of Intel Embree and Intel ISPC (Implicit SPMD Program Compiler), and fully exploits modern instruction sets like Intel SSE4, AVX, AVX2, AVX-512 and NEON to achieve high rendering performance, thus a CPU with support for at least SSE4.1 is required to run OSPRay on x86_64 architectures. -->\n",
    "\n",
    "### 2. Intel&reg; OSPRay features\n",
    "\n",
    "* **It is a library, not a visualization tool**. OSPRay is a _library_ that many different visualization tools can leverage.\n",
    "\n",
    "* **A rendering solution for visualization tools**. Visualization tools often rely on middleware libraries (such as VTK). OSPRay does not replace such middleware, and focuses exclusively on the rendering component. This way OSPRay gives additional choices for rendering.\n",
    "\n",
    "* **Focused on visualization rendering**. OSPRay emphasizes the rendering features needed for production and scientific visualization.\n",
    "\n",
    "* **Focused on HPC visualization rendering**. We explicitly focus on problems that remain challenging for visualization applications, such as large data, volume rendering and advanced shading. In particular, we effectively perform rendering using HPC resources. The use of OSPRay with GPUs is coming soon!\n",
    "<!-- * **Focused on performance**. Though we do not have to achieve game-like frame rates, our implementation makes efficient use of threading, vectorization, and, if desired, node-parallelism; and leverages the most efficient ray tracing technologies available. -->\n",
    "\n",
    "### 3. Intel OSPRay API\n",
    "The Intel OSPRay API is a layer between visualization applications and low-level hardware resources.\n",
    "<!-- The figure below shows the Intel OSPRay API in relation to other hardware and software components commonly found in visualization applications. -->\n",
    "The API is designed to be platform independent - this implementation targets CPUs, but the API should also map to GPUs, integrated graphics, and so on. It is a low level of abstraction similar to that of OpenGL*, which is the level that modern visualization tools use for rendering. Similar to solutions in OpenGL and GPGPU, Intel OSPRay API focuses on a low-level data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Figure3.png\" style=\"width:50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. API Categories\n",
    "The OSPRay API exposes the following categories of objects:\n",
    "\n",
    "* **OSPFrameBuffers** hold the final result of a rendered frame. Information held can contain, but is not limited to, pixel colors, depth values, and accumulation information.\n",
    "* **OSPData** are 1D data arrays, similar to “buffers” in a GPGPU context. In addition to the typical scalar and 2-, 3-, or 4-dimensional vector data, data arrays can also contain references to other actors (including to other data arrays), in device-abstract fashion.\n",
    "* **OSPGeometry** contain geometric surface primitives such as triangles, spheres, cylinders, etc.\n",
    "* **OSPVolumes** represent 3D scalar fields that can produce, for any 3D position, a scalar value that a volume renderer can sample.\n",
    "* **OSPTransferFunctions** map scalars to RGBA colors.\n",
    "* **OSPModels** are collections of geometries and volumes – the parent objects of the hierarchy. Time-varying data are vectors of OSP- Models.\n",
    "* **OSPCameras** generate primary rays for renderers to compute on.\n",
    "* **OSPRenderers** use cameras, models, etc, to render pixels. OSPRay defines two renderers: \n",
    "    * `scivis` renderer that combines many rendering techniques into a single renderer. In this renderer we focus on the needs of scientific visualization: we implement an OpenGL-like material model, with customizable contributions of transparency, shadows, ambient occlusion, and fully integrated volume rendering.\n",
    "    * `pathtracer` renderer, a fully photo-realistic renderer that can be used for generating high-quality publication images, and that has since seen adoption even outside of scientific visualization.\n",
    "* **OSPLights, OSPTextures, and OSPMaterials** specify additional inputs for rendering, lighting, shading, etc.\n",
    "\n",
    "\n",
    "#### Commit transactions\n",
    "An important aspect OSPRay is that parameters/data that affect any of the objects get passedx using **ospCommit(object)**.\n",
    "\n",
    "If a user wants to change the state of an existing object (e.g., to change the origin of an already existing camera) parameters have to be recommitted.\n",
    "\n",
    "Commiting is important to ensure performance and consistency for devices crossing a PCI* bus, or across a network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "### 5. First Lesson: ospTutorial\n",
    "\n",
    "In order to get a sense of basic API components we will work with the `ospTutorial.cpp` file which will create an image of two triangles, rendered with the pathtracer renderer.\n",
    "\n",
    "The image `firstFrame.png` shows the result after one call to `ospRenderFrame`. Jagged edges and noise in the shadow can be seen. These are not incorrect renderings but are the result of the random nature of ray tracing. In future lessons we will learn how to address this issue with `ospRenderFrame` which will converge the resulting image.\n",
    "\n",
    "#### 5.1 The Program Flow\n",
    "The following is a general flow for the ospTutorial.cpp program. Although these steps are described for this program, they can be generalized for other OSPRay codes.\n",
    "\n",
    "* Step 1 - Set up common objects to be used in the program\n",
    "* Step 2 - Initialize the renderer using ospInit()\n",
    "* Step 3 - Setup the camera and commit it\n",
    "* Step 4 - Setup the scene\n",
    "    * Step 4.1 - Feeding the model/vertex data to OSPRay\n",
    "    * Step 4.2 - Create a material \n",
    "    * Step 4.3 - Put mesh into a model and apply material and release mesh\n",
    "    * Step 4.4 - Put model into a group (collection of models), commit group and release model\n",
    "    * Step 4.5 - Put group into an instance (give the group a world transform), commit instance and release group\n",
    "    * Step 4.6 - Put instance in the world, commit world and release instance\n",
    "    * Step 4.7 - Create a light for Ambient Occlusion, and put light in world. Commit world and release light\n",
    "* Step 5  - Create the world bounds\n",
    "* Step 6  - Create renderer\n",
    "* Step 7  - Create and setup framebuffer\n",
    "* Step 8  - Render one frame\n",
    "* Step 9  - Access framebuffer and write the PNG file\n",
    "* Step 10 - Shutdown system and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/ospTutorial.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/ospTutorial.cpp\n",
    "// system includes\n",
    "#include <alloca.h>\n",
    "#include <errno.h>\n",
    "#include <stdint.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// ospray and math includes\n",
    "#include \"ospray/ospray_util.h\"\n",
    "#include \"rkcommon/math/rkmath.h\"\n",
    "#include \"rkcommon/math/vec.h\"\n",
    "\n",
    "// includes to STB for writing out a PNG image\n",
    "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
    "#include \"stb/stb_image_write.h\"\n",
    "\n",
    "using namespace rkcommon::math;\n",
    "\n",
    "// ################################################################################\n",
    "// A simple function that uses the STB library to write out the framebuffer in\n",
    "// PNG format.\n",
    "\n",
    "void writeHDPNG(const char *fileName, const vec2i &size, const float *pixel) {\n",
    "  constexpr int nChannels{4};\n",
    "  const int stride{nChannels * size.x};\n",
    "    /* Added for OIDN */\n",
    "  uint32_t* pxout = (uint32_t*)malloc(sizeof(uint32_t)*size.x*size.y);\n",
    "  for(size_t j = 0; j < size.y; j++) {\n",
    "   for(size_t i = 0; i < size.x; i++) {\n",
    "          //pxout[j * nChannels * size.x + i * nChannels + c] = (unsigned char)clamp(pixel[j * nChannels * size.x + i * nChannels + c] * 255.f, 0.f, 255.0f);\n",
    "       uint32_t r = (unsigned char)clamp(pixel[j * nChannels * size.x + i * nChannels] * 255.f, 0.f, 255.0f);\n",
    "       uint32_t g = (unsigned char)clamp(pixel[j * nChannels * size.x + i * nChannels + 1] * 255.f, 0.f, 255.0f);;\n",
    "       uint32_t b = (unsigned char)clamp(pixel[j * nChannels * size.x + i * nChannels + 2] * 255.f, 0.f, 255.0f);;\n",
    "       uint32_t a = (unsigned char)(clamp(pixel[j * nChannels * size.x + i * nChannels + 3] * 255.f, 0.f, 255.0f));\n",
    "       pxout[j * size.x + i] = (a << 24) | (b << 16) | (g << 8) | r;\n",
    "       //Repack the color channels\n",
    "       //Example for r... here are is where r should be for the pxout array of uint32_t objects: 0x000000000000FFFFh\n",
    "       //Example for r in a binary representation of the above 0x00000000000000000000000011111111b\n",
    "       //Example for g... here are is where g should be for the pxout array of uint32_t objects: 0x00000000FFFF0000h\n",
    "       //Example for g in a binary representation of the above 0x00000000000000001111111100000000b\n",
    "   }\n",
    "  }\n",
    "        \n",
    "  stbi_write_png(fileName, size.x, size.y, nChannels, pxout, stride);\n",
    "  if(pxout) { \n",
    "      free(pxout);\n",
    "      pxout = 0;\n",
    "  }\n",
    "}\n",
    "      \n",
    "void writePNG(const char *fileName, const vec2i &size, const uint32_t *pixel) {\n",
    "  constexpr int nChannels{4};\n",
    "  const int stride{nChannels * size.x};  \n",
    "  stbi_write_png(fileName, size.x, size.y, nChannels, pixel, stride);\n",
    "\n",
    "}\n",
    "\n",
    "// ################################################################################\n",
    "// The entry point into the program that exercises the API\n",
    "\n",
    "int main(int argc, const char **argv) {\n",
    "\n",
    "\n",
    "  // ########## Step 1 - Set up common objects to be used in the program\n",
    "\n",
    "  // Define the width and height of the framebuffer\n",
    "  // image size\n",
    "  vec2i imgSize;\n",
    "  imgSize.x = 1024;  // width\n",
    "  imgSize.y = 768;   // height\n",
    "\n",
    "  // camera\n",
    "  // Placing the camera at the origin <0,0,0>\n",
    "  float cam_pos[] = {0.f, 0.f, 0.f};\n",
    "\n",
    "  // Orient the camera noting Y-up\n",
    "  float cam_up[] = {0.f, 1.f, 0.f};\n",
    "\n",
    "  // set the camera view direction\n",
    "  float cam_view[] = {0.1f, 0.f, 1.f};\n",
    "\n",
    "  // triangle mesh data\n",
    "  // 4 vertices each with a XYZ position\n",
    "  float vertex[] = {\n",
    "    -1.0f, -1.0f, 3.0f, \n",
    "    -1.0f, 1.0f, 3.0f,\n",
    "    1.0f, -1.0f, 3.0f, \n",
    "    0.1f,  0.1f, 0.3f};\n",
    "\n",
    "  // 4 colors denoted by RGBA\n",
    "  float color[] = {\n",
    "    0.9f, 0.5f, 0.5f, 1.0f, \n",
    "    0.8f, 0.8f, 0.8f, 1.0f,\n",
    "    0.8f, 0.8f, 0.8f, 1.0f, \n",
    "    0.5f, 0.9f, 0.5f, 1.0f};\n",
    "\n",
    "  // index for the triangles\n",
    "  int32_t index[] = {0, 1, 2, 1, 2, 3};\n",
    "\n",
    "\n",
    "  // ########## Step 2 - Initialize the renderer using ospInit()\n",
    "    printf(\"initialize OSPRay...\");\n",
    "\n",
    "  // initialize OSPRay; OSPRay parses (and removes) its commandline parameters,\n",
    "  // It is the first thing to do in OSPRay\n",
    "  OSPError init_error = ospInit(&argc, argv);\n",
    "  if (init_error != OSP_NO_ERROR)\n",
    "    return init_error;\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "    \n",
    "    //load denoiser module\n",
    "   if( !(ospLoadModule(\"denoiser\") == OSP_NO_ERROR )) {\n",
    "       printf(\"error loading ospray denoiser\\n\");\n",
    "    exit(-1);\n",
    "   }\n",
    "  \n",
    "\n",
    "  // ########## Step 3 - Setup the camera and commit it\n",
    "  printf(\"setting up camera...\");\n",
    "\n",
    "  // Feeding the camera data to OSPRay\n",
    "  // create and setup camera\n",
    "  OSPCamera camera = ospNewCamera(\"perspective\");\n",
    "  ospSetFloat(camera, \"aspect\", imgSize.x / (float)imgSize.y);\n",
    "  // ospSetParam passes data to objects\n",
    "  // We pass \"position\" to the camera object, position type = OSP_VEC3F with value = cam_pos\n",
    "  ospSetParam(camera, \"position\",  OSP_VEC3F, cam_pos); \n",
    "  ospSetParam(camera, \"direction\", OSP_VEC3F, cam_view);\n",
    "  ospSetParam(camera, \"up\",        OSP_VEC3F, cam_up);\n",
    "  ospCommit(camera);  // commit each object to indicate modifications are done\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "\n",
    "  // ########## Step 4 - Setup the scene\n",
    "  printf(\"setting up scene...\");\n",
    "\n",
    "  // #################### Step 4.1 Feeding the model/vertex data to OSPRay\n",
    "  // create OSPData-type variable named data with value = vertex\n",
    "  // commit it\n",
    "  // create OSPGeometry-type geometry named mesh,\n",
    "  // put data into mesh in the attribute named \"vertex.position\"\n",
    "  // release data\n",
    "  // commit mesh\n",
    "  OSPData data = ospNewSharedData1D(vertex, OSP_VEC3F, 4);\n",
    "  ospCommit(data);\n",
    "  OSPGeometry mesh = ospNewGeometry(\"mesh\");\n",
    "  ospSetObject(mesh, \"vertex.position\", data);\n",
    "  ospRelease(data);  // we are done using this handle\n",
    "\n",
    "  // repeat for color instead of vertex\n",
    "  data = ospNewSharedData1D(color, OSP_VEC4F, 4);\n",
    "  ospCommit(data);\n",
    "  ospSetObject(mesh, \"vertex.color\", data);\n",
    "  ospRelease(data);\n",
    "\n",
    "  // repeat for index instead of color\n",
    "  data = ospNewSharedData1D(index, OSP_VEC3UI, 2);\n",
    "  ospCommit(data);\n",
    "  ospSetObject(mesh, \"index\", data);\n",
    "  ospRelease(data);\n",
    "\n",
    "  ospCommit(mesh);\n",
    "\n",
    "  // #################### Step 4.2 - Create a material\n",
    "  // create OSPMaterial-type variable named mat and commit it\n",
    "  OSPMaterial mat = ospNewMaterial(\"pathtracer\", \"obj\");\n",
    "  ospCommit(mat);\n",
    "\n",
    "  // #################### Step 4.3 - Put mesh into a model and apply material and release mesh\n",
    "  // create OSPGeometricModel-type variable named model and commit it\n",
    "  // OSPGeometricModel = OSPGeometry + OSPMaterial\n",
    "  OSPGeometricModel model = ospNewGeometricModel(mesh);\n",
    "  ospSetObject(model, \"material\", mat);\n",
    "  ospCommit(model);\n",
    "  ospRelease(mesh);\n",
    "  ospRelease(mat);\n",
    "\n",
    "  // #################### Step 4.4 - Put model into a group (collection of models), commit group and release model\n",
    "  // create OSPGroup-type variable named group and add model into group\n",
    "  // OSPGroup = OSPGeometricModel(several if required) + lights (In this case there is no light) but the creation of group is still necessary\n",
    "  // In out case our group has only one model and zero lights\n",
    "  OSPGroup group = ospNewGroup();\n",
    "  ospSetObjectAsData(group, \"geometry\", OSP_GEOMETRIC_MODEL, model);\n",
    "  ospCommit(group);\n",
    "  ospRelease(model);\n",
    "\n",
    "  /// #################### Step 4.5 - Put group into an instance (give the group a world transform), commit instance and release group\n",
    "  // create OSPInstance-type variable names instance\n",
    "  // Instances in OSPRay represent a single group’s placement into the world via a transform\n",
    "  OSPInstance instance = ospNewInstance(group);\n",
    "  ospCommit(instance);\n",
    "  ospRelease(group);\n",
    "\n",
    "  // #################### Step 4.6 - Put instance in the world, commit world and release instance\n",
    "  // World is a container of scene data represented by instances.\n",
    "  // create OSPWorld-type variable named world, put instance in world and release instance\n",
    "  OSPWorld world = ospNewWorld();\n",
    "  ospSetObjectAsData(world, \"instance\", OSP_INSTANCE, instance);\n",
    "  ospRelease(instance);\n",
    "\n",
    "  // #################### Step 4.7 - Create a light for Ambient Occlusion, and put light in world. Commit world and release light\n",
    "  // create OSPLight-type variable named light, put light in the world, commit world and release light\n",
    "  OSPLight light = ospNewLight(\"ambient\");\n",
    "  ospCommit(light);\n",
    "  ospSetObjectAsData(world, \"light\", OSP_LIGHT, light);\n",
    "  ospRelease(light);\n",
    "\n",
    "  ospCommit(world);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "\n",
    "  // ########## Step 5 - Create the world bounds\n",
    "  // create OSPBounds-type bounds named liworldBoundsght\n",
    "  // once the world has been setup we can carry out the bounds\n",
    "  OSPBounds worldBounds = ospGetBounds(world);\n",
    "  printf(\"\\nworld bounds: ({%f, %f, %f}, {%f, %f, %f}\\n\\n\",\n",
    "         worldBounds.lower[0], worldBounds.lower[1], worldBounds.lower[2],\n",
    "         worldBounds.upper[0], worldBounds.upper[1], worldBounds.upper[2]);\n",
    "\n",
    "\n",
    "  // ########## Step 6 - Create renderer\n",
    "  // create OSPRenderer-type renderer named renderer\n",
    "  OSPRenderer renderer = ospNewRenderer(\"pathtracer\");  // choose between pathtracer or scivis\n",
    "  ospSetFloat(renderer, \"backgroundColor\", 1.0f);  // white, transparent\n",
    "  ospCommit(renderer);\n",
    "  printf(\"setting up renderer...\");\n",
    "\n",
    "\n",
    "  // ########## Step 7 - Create and setup framebuffer\n",
    "  // The framebuffer holds the rendered 2D image\n",
    "  // Its arguments are object size in pixels, format, color, and channel use\n",
    "  // These are the allowed formats:\n",
    "      // OSP_FB_NONE:    framebuffer will not be mapped by the application\n",
    "      // OSP_FB_RGBA8:   bit [0–255] linear component red, green, blue, alpha\n",
    "      // OSP_FB_SRGBA:   bit sRGB gamma encoded color components, and linear alpha\n",
    "      // OSP_FB_RGBA32F: 32 bit float components red, green, blue, alpha\n",
    "//  OSPFrameBuffer framebuffer =\n",
    "//    ospNewFrameBuffer(imgSize.x, imgSize.y, OSP_FB_SRGBA,\n",
    "//                      OSP_FB_COLOR | /*OSP_FB_DEPTH |*/ OSP_FB_ACCUM);\n",
    "    \n",
    "    OSPFrameBuffer framebuffer =\n",
    "      ospNewFrameBuffer(imgSize.x, imgSize.y, OSP_FB_RGBA32F,\n",
    "                        OSP_FB_COLOR | /*OSP_FB_DEPTH |*/ OSP_FB_ACCUM);\n",
    "  \n",
    "   \n",
    "// OIDN implementation start \n",
    "   OSPImageOperation imops[1];\n",
    "   imops[0] = ospNewImageOperation(\"denoiser\");\n",
    "   ospCommit(imops[0]);\n",
    "   data = ospNewSharedData1D(imops, OSP_IMAGE_OPERATION, 1);\n",
    "   ospCommit(data);\n",
    "   ospSetObject(framebuffer, \"imageOperation\", data);  \n",
    "   ospCommit(framebuffer);\n",
    "// OIDN implementation end \n",
    "\n",
    "  ospResetAccumulation(framebuffer);\n",
    "\n",
    "  printf(\"rendering initial frame to firstFrame.png...\");\n",
    "\n",
    "\n",
    "  // ########## Step 8 - Render one frame\n",
    "  ospRenderFrameBlocking(framebuffer, renderer, camera, world);\n",
    "\n",
    "\n",
    "  // ########## Step 9 - Access framebuffer and write its content as PNG file\n",
    "//  const uint32_t *fb = (uint32_t *)ospMapFrameBuffer(framebuffer, OSP_FB_COLOR);\n",
    "//  writePNG(\"firstFrame.png\", imgSize, fb);\n",
    "  const float *fb = (float *)ospMapFrameBuffer(framebuffer, OSP_FB_COLOR);\n",
    "  writeHDPNG(\"firstFrame_Denoised.png\", imgSize, fb);\n",
    "  ospUnmapFrameBuffer(fb, framebuffer);\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "\n",
    "  // ########## Step 10 - Shutdown system and clean up\n",
    "  printf(\"\\ncleaning up objects...\");\n",
    "  ospRelease(renderer);\n",
    "  ospRelease(camera);\n",
    "  ospRelease(framebuffer);\n",
    "  ospRelease(world);\n",
    "    \n",
    "    /* added for denoiser */\n",
    "  ospRelease(data);\n",
    "  ospRelease(imops[0]);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  ospShutdown();\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ":: initializing oneAPI environment ...\n",
      "   build.sh: BASH_VERSION = 5.1.16(1)-release\n",
      "   args: Using \"$@\" for setvars.sh arguments: --force\n",
      ":: advisor -- latest\n",
      ":: ccl -- latest\n",
      ":: compiler -- latest\n",
      ":: dal -- latest\n",
      ":: debugger -- latest\n",
      ":: dev-utilities -- latest\n",
      ":: dnnl -- latest\n",
      ":: dpcpp-ct -- latest\n",
      ":: dpl -- latest\n",
      ":: embree -- latest\n",
      ":: inspector -- latest\n",
      ":: intelpython -- latest\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      "\n",
      "CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.\n",
      "To initialize your shell, run\n",
      "\n",
      "    $ conda init <SHELL_NAME>\n",
      "\n",
      "Currently supported shells are:\n",
      "  - bash\n",
      "  - fish\n",
      "  - tcsh\n",
      "  - xonsh\n",
      "  - zsh\n",
      "  - powershell\n",
      "\n",
      "See 'conda init --help' for more information and options.\n",
      "\n",
      "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
      "\n",
      "\n",
      ":: ipp -- latest\n",
      ":: ippcp -- latest\n",
      ":: ispc -- latest\n",
      ":: itac -- latest\n",
      ":: mkl -- latest\n",
      ":: modelzoo -- latest\n",
      ":: modin -- latest\n",
      ":: mpi -- latest\n",
      ":: neural-compressor -- latest\n",
      ":: oidn -- latest\n",
      ":: openpgl -- latest\n",
      ":: openvkl -- latest\n",
      ":: ospray -- latest\n",
      ":: ospray_studio -- latest\n",
      ":: pytorch -- latest\n",
      ":: rkcommon -- latest\n",
      ":: rkutil -- latest\n",
      ":: tbb -- latest\n",
      ":: tensorflow -- latest\n",
      ":: vtune -- latest\n",
      ":: oneAPI environment initialized ::\n",
      " \n",
      "## ue67fcfb20b4827a1ed6842c10ec58c1 is compiling O2_OSPRay_Intro\n",
      "-- The C compiler identification is GNU 11.4.0\n",
      "-- The CXX compiler identification is GNU 11.4.0\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Check for working C compiler: /usr/bin/cc - skipped\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Embree v4.1.0: /opt/intel/oneapi/embree/4.1.0/lib/libembree4.so.4\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "-- Found Threads: TRUE  \n",
      "-- Found Open VKL v1.3.2: /opt/intel/oneapi/openvkl/1.3.2/lib/libopenvkl.so.1.3.2\n",
      "-- Found OSPRay: /opt/intel/oneapi/ospray/2.12.0\n",
      "-- ONEAPI_ROOT: /opt/intel/oneapi\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/ue67fcfb20b4827a1ed6842c10ec58c1/Training/Renderkit_w/OSPRay_1_Intro/build\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/ospTutorial.dir/src/ospTutorial.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ../bin/ospTutorial\u001b[0m\n",
      "[100%] Built target ospTutorial\n"
     ]
    }
   ],
   "source": [
    "! ./build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Run the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ue67fcfb20b4827a1ed6842c10ec58c1 is running O2_OSPRay_Intro\n",
      "initialize OSPRay...done!\n",
      "setting up camera...done!\n",
      "setting up scene...done!\n",
      "\n",
      "world bounds: ({-1.000000, -1.000000, 0.300000}, {1.000000, 1.000000, 3.000000}\n",
      "\n",
      "setting up renderer...rendering initial frame to firstFrame.png...done!\n",
      "\n",
      "cleaning up objects...done!\n"
     ]
    }
   ],
   "source": [
    "! ./run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Resulting Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Summary\n",
    "\n",
    "You have arrived at the end of this lesson. During this lesson, you:\n",
    "\n",
    "* Defined what Intel® OSPRay is about.\n",
    "* Defined the goals of Intel® OSPRay.\n",
    "* Summarized the program flow and OSPRay API to write a minimal viewer program for displaying mesh geometry.\n",
    "\n",
    "***\n",
    "## Resources\n",
    "* M. Pharr and G. Humphreys. Physically Based Rendering: From Theory to Implementation. Morgan Kaufman, 3rd edition, 2016.\n",
    "* P. Shirley. Ray Tracing in One Weekend Series. Editors: Steve Hollasch, Trevor David Black. Version/Edition: v3.2.0. Date: 2020-07-18. URL (series): https://raytracing.github.io/\n",
    "* I. Wald et al., \"OSPRay - A CPU Ray Tracing Framework for Scientific Visualization,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 23, no. 1, pp. 931-940, Jan. 2017, doi: 10.1109/TVCG.2016.2599041."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<html><body><span style=\"color:green\"><h1>Next: An Example of Intel® OSPRay Techniques and Procedural Scenes</h1></span></body></html>\n",
    "\n",
    "[Click Here](../osp2_ospExamples/ospExamples.ipynb)\n",
    "\n",
    "<html><body><span style=\"color:green\"><h1>Back: Overview</h1></span></body></html>\n",
    "\n",
    "[Click Here](../Overview.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
